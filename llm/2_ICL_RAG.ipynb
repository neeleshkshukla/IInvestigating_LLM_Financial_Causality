{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e8f077b-0309-4a63-880f-5f6a04c58293",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -q langchain openai chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c359519c-939f-44ef-be3a-09d9b41ba666",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.document_loaders.dataframe import DataFrameLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA, MapReduceChain, MapReduceDocumentsChain, StuffDocumentsChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "import tiktoken\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6919ba0c-a878-415d-b994-e9c716f8ea27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "USE_GPT_3_5_TURBO = False\n",
    "USE_GPT_4 = True\n",
    "USE_ZERO_SHOT = False\n",
    "USE_FEW_SHOT = True\n",
    "NUM_FEW_SHOT_EXAMPLES = 5\n",
    "USE_RAG_FEW_SHOT = True\n",
    "\n",
    "DATASET_PATH = 'Research/FNP_2023/'\n",
    "OUTPUT_DIR = 'Research/FNP_2023/'\n",
    "PRACTICE_SPANISH_DIR = 'practice_spanish'\n",
    "PRACTICE_ENGLISH_DIR = 'practice-english'\n",
    "TRAIN_SPANISH_DIR = 'training_spanish'\n",
    "TRAIN_ENGLISH_DIR = 'training-english'\n",
    "IS_PRACTICE = True\n",
    "IS_TRAINING= False\n",
    "IS_ENGLISH = False\n",
    "IS_SPANISH = True\n",
    "\n",
    "GPT4_DEPLOYMENT_NAME = ''\n",
    "GPT_3_5_DEPLOYMENT_NAME = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90e5f398-49b7-40bd-b14c-7cda11f2ed2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if USE_GPT_4:\n",
    "    model = AzureChatOpenAI(temperature=0,deployment_name=GPT4_DEPLOYMENT_NAME)\n",
    "elif USE_GPT_3_5_TURBO:\n",
    "    model = AzureChatOpenAI(temperature=0,deployment_name=GPT_3_5_DEPLOYMENT_NAME)\n",
    "else:\n",
    "    raise Exception('Model not supported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acd8e6a0-6da1-44cf-ad71-ca4255053710",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='cause', description='extract cause from the user given text', type='string'), ResponseSchema(name='effect', description='extract effect from the user given text', type='string')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"cause\", description=\"extract cause from the user given text\"),\n",
    "    ResponseSchema(name=\"effect\", description=\"extract effect from the user given text\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d718377-ad51-48b4-ad86-abec4e0ce0da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## zero shot prompt tempelate\n",
    "\n",
    "zero_shot_template = \"\"\"\n",
    "        The task is to extract the cause and effect from the given financial {text}. Don't provide anything except cause and effect.\n",
    "        \n",
    "        Instructions:\n",
    "        - Answer the question based only on the text provided. Extracted cause and effect should be part of given input financial text.\n",
    "        - Only one set of Cause and effect has to be given as output for each single input.\n",
    "        - Output language has to be the same as the input language.\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d105b58-d958-4639-b911-7c0fbcfa49a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Few shot template\n",
    "\n",
    "few_shot_template = \"\"\"\n",
    "        The task is to extract the cause and effect from the given financial {text}. Don't provide anything except cause and effect. \n",
    "        \n",
    "        Here are few examples:\n",
    "\n",
    "        {few_shot_examples}\n",
    "        \n",
    "        \n",
    "        Instructions:\n",
    "        - Answer the question based only on the text provided. Extracted cause and effect should be part of given input financial text.\n",
    "        - Only one set of Cause and effect has to be given as output for each single input.\n",
    "        - Output language has to be the same as the input language.\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Few shot template: Spanish\n",
    "\n",
    "few_shot_template = \"\"\"\n",
    "        La tarea es extraer la causa y el efecto del {text} financiero dado. No proporciones nada excepto causa y efecto. \n",
    "        \n",
    "        Aquí hay algunos ejemplos:\n",
    "\n",
    "        {few_shot_examples}\n",
    "        \n",
    "        \n",
    "        Instrucciones:\n",
    "        - Responda la pregunta basándose únicamente en el texto proporcionado. La causa y el efecto extraídos deben ser parte del texto financiero de entrada dado.\n",
    "        - Solo se debe dar un conjunto de Causa y efecto como salida para cada entrada individual.\n",
    "        - El idioma de salida tiene que ser el mismo que el de entrada.\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af68a69-d421-4819-b36c-a82f96bca917",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt():\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "    if USE_ZERO_SHOT:\n",
    "        print('Zero shot setting')\n",
    "        prompt_template = zero_shot_template\n",
    "        input_vars = [\"text\"]\n",
    "    elif USE_FEW_SHOT:\n",
    "        print('Few shot setting')\n",
    "        prompt_template = few_shot_template\n",
    "        input_vars = [\"text\", \"few_shot_examples\"]\n",
    "    else:\n",
    "        raise Exception('Learning method not supported!')\n",
    "        \n",
    "        \n",
    "    prompt = ChatPromptTemplate(\n",
    "        messages=[\n",
    "            HumanMessagePromptTemplate.from_template(prompt_template)\n",
    "        ],\n",
    "        input_variables=input_vars,\n",
    "        partial_variables={\"format_instructions\": format_instructions}\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7890fceb-fe25-4014-8a51-2bd51e3bd640",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_cause_effect(text, prompt, few_shot_examples=''):\n",
    "    if USE_ZERO_SHOT:\n",
    "        _input = prompt.format_prompt(text=text)\n",
    "\n",
    "    elif USE_FEW_SHOT:\n",
    "        _input = prompt.format_prompt(text=text, few_shot_examples=few_shot_examples)\n",
    "\n",
    "    output = model(_input.to_messages())\n",
    "    response = output_parser.parse(output.content)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e916f72a-41ad-4fb6-ae18-43a2d4bfa669",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e679093/Desktop/Research/FNP_2023/venv_fnp_python_3_11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "# Check if the flag for using the RAG few-shot setup is enabled\n",
    "if USE_RAG_FEW_SHOT :\n",
    "    if IS_ENGLISH:\n",
    "        training_df = pd.read_csv('Research/FNP_2023/FinCausal/dataset/training_subtask_en.csv', sep=';')\n",
    "    if IS_SPANISH:\n",
    "        training_df = pd.read_csv('Research/FNP_2023/FinCausal/dataset/training_subtask_es.csv', sep=';')\n",
    "        \n",
    "    training_df = training_df[['Text', 'Cause', 'Effect']]\n",
    "    loader = DataFrameLoader(training_df, page_content_column='Text')\n",
    "    loaded_data = loader.load()\n",
    "\n",
    "    # Create embeddings using the OpenAIEmbeddings class\n",
    "    #embeddings = OpenAIEmbeddings(deployment=\"embeddings_model\", chunk_size=1)\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Create an index creator using the VectorstoreIndexCreator class\n",
    "    #index_creator = VectorstoreIndexCreator(embedding=embeddings)\n",
    "\n",
    "    # Create a searchable index of documents using the loaded data\n",
    "    #docsearch = index_creator.from_loaders([loader])\n",
    "    #doc_search = Chroma.from_documents(loaded_data, OpenAIEmbeddings(deployment = \"embeddings_model\", chunk_size=1))\n",
    "    doc_search = Chroma.from_documents(loaded_data, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bf53ddd-f068-4b91-84aa-0c50eb8f86f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_simialr_examples(content) : \n",
    "    # NUM_FEW_SHOT_EXAMPLES\n",
    "    query_response = doc_search.similarity_search(content, k=NUM_FEW_SHOT_EXAMPLES)\n",
    "    return query_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeba553d-e0e8-4811-a129-561fa9b83989",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few shot setting\n"
     ]
    }
   ],
   "source": [
    "prompt = build_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ae2cc9e-9730-4e63-8a80-ff54bdc15261",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if IS_ENGLISH:\n",
    "    practice_df = pd.read_csv('Research/FNP_2023/FinCausal/dataset/practice-english/practice_subtask_en.csv', sep=';')\n",
    "if IS_SPANISH:\n",
    "    practice_df = pd.read_csv('Research/FNP_2023/FinCausal/dataset/practice_spanish/practice_subtask_es.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f0f9cdb-59d6-421d-a8cc-6e5a12829d2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_few_shot_examples(content):\n",
    "    few_shot_example = ''\n",
    "    response = get_simialr_examples(content)\n",
    "    for i in range(len(response)):\n",
    "        text = response[i].page_content\n",
    "        cause = response[i].metadata['Cause']\n",
    "        effect = response[i].metadata['Effect']\n",
    "        few_shot_example = few_shot_example + 'Example ' + str(i+1) + ':\\n'\n",
    "        few_shot_example = few_shot_example + 'Text: ' + text + '\\n'\n",
    "        few_shot_example = few_shot_example + 'cause: ' + cause + '\\n'\n",
    "        few_shot_example = few_shot_example + 'effect: ' + effect + '\\n'\n",
    "    return few_shot_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_list = []\n",
    "effect_list = []\n",
    "index_list = []\n",
    "offset = 0\n",
    "for i in range(len(practice_df)):\n",
    "    print(f\"Processing Input {i+offset}\")\n",
    "    input_text = practice_df['Text'][i+offset]\n",
    "    cause = practice_df['Cause'][i+offset]\n",
    "    effect = practice_df['Effect'][i+offset]\n",
    "    \n",
    "    if USE_RAG_FEW_SHOT:\n",
    "        few_shot_examples = get_few_shot_examples(input_text)\n",
    "        #print(few_shot_examples)\n",
    "        response = get_cause_effect(input_text, prompt,few_shot_examples)\n",
    "        #print(response)\n",
    "    else:\n",
    "        response = get_cause_effect(input_text, prompt)\n",
    "    cause_list.append(response['cause'])\n",
    "    effect_list.append(response['effect'])\n",
    "    index_list.append(practice_df['Index'][i+offset]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fincaual_df = pd.DataFrame(columns=['Index', 'Text', 'Cause', 'Effect'])\n",
    "fincaual_df['Index'] = index_list\n",
    "fincaual_df['Text'] = practice_df['Text'].values\n",
    "fincaual_df['Cause'] = cause_list\n",
    "fincaual_df['Effect'] = effect_list\n",
    "fincaual_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81b2f55b-9351-4545-bf0d-15e897407e3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if IS_ENGLISH:\n",
    "    fincaual_df.to_csv(os.path.join('Research/FNP_2023/FinCausal/output/llm/OpenAI/practice-english', 'few_shot_'+str(NUM_FEW_SHOT_EXAMPLES)+'_'+'practice_subtask_results_en.csv'), sep=';', escapechar='\"', index=False)\n",
    "if IS_SPANISH:\n",
    "    fincaual_df.to_csv(os.path.join('Research/FNP_2023/FinCausal/output/llm/OpenAI/practice_spanish', 'few_shot_'+str(NUM_FEW_SHOT_EXAMPLES)+'_'+'practice_subtask_results_es.csv'), sep=';', escapechar='\"', index=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "OpenAI-RAG",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
